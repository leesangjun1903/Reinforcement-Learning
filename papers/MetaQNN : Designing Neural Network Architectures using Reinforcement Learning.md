# MetaQNN : Designing Neural Network Architectures using Reinforcement Learning | Image classification, Reinforcement Learning

# 핵심 요약

**MetaQNN** 논문은 *강화 학습(Reinforcement Learning)*을 이용해 **인간의 개입 없이** 고성능 CNN(CNN) 구조를 자동 설계하는 **MetaQNN** 프레임워크를 제안한다. Q-러닝 기반 에이전트는 CNN의 각 레이어를 순차적으로 선택하며, 검증 정확도를 보상으로 사용해 최적의 네트워크 토폴로지를 탐색·학습한다.

# 1. 문제 정의 및 배경  
전통적으로 CNN 구조 설계는 전문가의 경험과 시행착오에 의존해 수많은 하이퍼파라미터(레이어 수·순서·필터 크기·뉴런 수 등)를 수동으로 조정해야 한다. 이 과정은  
- 탐색 공간이 **거대**  
- 설계 **효율성** 저하  
- **전이 학습**에 최적화된 아키텍처 발굴 어려움  
등의 한계를 지닌다.

# 2. 제안 방법  
## 2.1. MDP(마르코프 결정 과정) 구성  
- **상태(s)**: 현재까지 선택된 레이어들의 유형 및 파라미터(필터 수, receptive field, representation size 등)  
- **행동(a)**: 다음에 추가할 레이어 유형(C, P, FC, GAP, SM) 및 하이퍼파라미터 선택  
- **보상(r)**: 설계된 네트워크를 주어진 데이터셋에서 학습한 뒤 검증 정확도

## 2.2. Q-러닝 업데이트  
에이전트는 ϵ-탐욕(ϵ-greedy) 전략으로 **탐색(exploitation)** 과 **활용(exploitation)** 을 조절하며, 경험 재생(experience replay)을 활용해 Q값을 갱신한다.  
– Bellman 업데이트 식:  

$$
Q(s,a) \leftarrow (1-\alpha)\,Q(s,a) + \alpha\bigl[r + \gamma \max_{a'} Q(s',a')\bigr]
$$  

– 학습률 α=0.01, 할인율 γ=1으로 설정  
– ϵ 스케줄: 1.0→0.1 단계별 감소, 각 단계별 샘플링 모델 수 별도 지정  

## 2.3. 탐색 공간 제약  
- **레이어 깊이 제한**: 최대 12개  
- **Representation size** 이산화(3개 구간)로 pooling 및 stride 후 추이 제어  
- **FC 레이어** 최대 2개, 뉴런 수 비증가 제약  
- 연속 pooling 금지 등으로 DAG(비순환 그래프) 보장  

# 3. 모델 구조 및 학습  
- 탐색 단계: CIFAR-10/100, SVHN, MNIST 각각에 대해 20 에폭, Adam 최적화, 드롭아웃 증가 스케줄 적용  
- 파인튜닝 단계: 상위 5개 모델을 장기 학습(최대 300 에폭 이상), 데이터 증강(이미지, 대비 정규화 등) 적용  
- 앙상블 구성으로 추가 성능 향상  

# 4. 성능 및 한계  
| 데이터셋 | Top-1 오류율 | 앙상블 오류율 |
|----------|--------------|--------------|
| CIFAR-10 | 6.92%        | 7.32%        |
| SVHN     | 2.28%        | 2.06%        |
| MNIST    | 0.44%        | 0.32%        |
| CIFAR-100| 27.14%       | –            |

- **비교**: 동종 레이어만 사용한 수작업 모델 대비 **최고 성능** 달성  
- **경쟁력**: Residual, ELU, TreePool 등 복잡 레이어 포함 최신 모델과 유사 수준  
- **한계**:  
  - 탐색 비용이 매우 높아(수백 GPU-일) 실용적 제약  
  - 하이퍼파라미터 튜닝 불포괄적(모든 모델에 동일 스케줄)  
  - Representation size 이산화로 인한 설계 불확실성  

# 5. 일반화 성능 향상 가능성  
- **Transfer Learning**: CIFAR-10용 최적 모델을 CIFAR-100·SVHN·MNIST에 그대로 적용했을 때도 높은 정확도 유지  
- **앙상블 효과**: 다수의 근사 최적 모델을 조합해 과적합 완화 및 안정성 증가  
- **메타 학습**: 다양한 데이터셋에 걸친 메타Q-러닝으로 모델 설계 편차 감소  

# 6. 미래 영향 및 고려 사항  
- **영향**:  
  - 네트워크 아키텍처 자동화 연구 가속화  
  - AutoML, Neural Architecture Search(NAS) 분야의 초기 표준 수립  
  - 하드웨어·메모리 제약을 반영한 제약 기반 설계 연구 촉진  

- **고려 사항**:  
  - Q-함수 근사(딥 Q-러닝) 도입으로 대규모 탐색 공간 확장  
  - 하이퍼파라미터 동시 최적화 기법(TPE, Bayesian Optim.) 결합  
  - 탐색 효율화를 위한 탐욕-탐색 전략 개선(Thompson Sampling 등)  
  - 연산·메모리·전력 예산 제약을 보상에 반영해 경량 모델 자동 설계  

이 논문은 강화 학습 기반 자동 아키텍처 설계의 가능성을 제시하며, 향후 NAS와 AutoML 연구에 중요한 이정표로 작용할 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/46d76799-dddf-4804-9b38-2acadd2b3fd8/1611.02167v3.pdf
